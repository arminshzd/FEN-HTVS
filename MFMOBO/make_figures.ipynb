{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "from gpytorch.likelihoods import FixedNoiseGaussianLikelihood\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "\n",
    "from gskgpr import GaussianStringKernelGP\n",
    "from seq2ascii import Seq2Ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "REF_POINT = torch.Tensor([-50, -50])\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_res(pcc, data_dir):\n",
    "    with open(f\"{data_dir}/{pcc}_FEN.JSON\") as f:\n",
    "        rep = json.load(f)\n",
    "    F_fen = rep[\"FE\"]\n",
    "    F_fen_err = rep[\"FE_error\"]\n",
    "\n",
    "    with open(f\"{data_dir}/{pcc}_DEC.JSON\") as f:\n",
    "        rep = json.load(f)\n",
    "    F_dec = rep[\"FE\"]\n",
    "    F_dec_err = rep[\"FE_error\"]\n",
    "    return {\"PCC\": [rep[\"PCC\"]], \"F_FEN\": [float(F_fen)], \"err_FEN\": [float(F_fen_err)],\n",
    "             \"F_DEC\": [float(F_dec)], \"err_DEC\": [float(F_dec_err)]}\n",
    "\n",
    "def load_data(data_dir):\n",
    "    PCC_list = []\n",
    "    for folder in os.listdir(data_dir):\n",
    "        if re.match(\"[A-Z]{5}_[A-Z]{3}\", folder):\n",
    "            PCC_list.append(folder.split(\"_\")[0])\n",
    "\n",
    "    PCC_list = set(PCC_list)\n",
    "    data = []\n",
    "    for pcc in PCC_list:\n",
    "        try:\n",
    "            data.append(pd.DataFrame(load_json_res(pcc, data_dir)))\n",
    "        except:\n",
    "            print(f\"Skipping {pcc}.\")\n",
    "\n",
    "    data = pd.concat(data)\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    return data\n",
    "\n",
    "def initialize_model(train_x, train_y, err_y, translator):\n",
    "    models = [\n",
    "        GaussianStringKernelGP(train_x=train_x, train_y=train_y[:, 0], \n",
    "                            likelihood=FixedNoiseGaussianLikelihood(noise=err_y[:, 0]), \n",
    "                            translator=translator),\n",
    "        GaussianStringKernelGP(train_x=train_x, train_y=train_y[:, 1],\n",
    "                            likelihood=FixedNoiseGaussianLikelihood(noise=err_y[:, 1]), \n",
    "                            translator=translator)\n",
    "    ]\n",
    "    model = ModelListGP(*models).to(device)\n",
    "    mll = SumMarginalLogLikelihood(model.likelihood, model).to(device)\n",
    "    return model, mll\n",
    "\n",
    "def fit_gpytorch_model(mll, optimizer, n_iters=100):\n",
    "    for i in range(n_iters):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = mll.model(*mll.model.train_inputs)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, mll.model.train_targets)\n",
    "        loss.backward()\n",
    "        print('Iter %d/%d - Loss: %.3f   sigma11: %.3f   sigma21: %.3f   sigma12: %.3f   sigma22: %.3f' % (\n",
    "            i + 1, n_iters, loss.item(),\n",
    "            mll.model.models[0].covar_module.sigma1.item(),\n",
    "            mll.model.models[0].covar_module.sigma2.item(),\n",
    "            mll.model.models[1].covar_module.sigma1.item(),\n",
    "            mll.model.models[1].covar_module.sigma2.item(),\n",
    "        ))\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data(\"/project2/andrewferguson/armin/FE_DATA/results/\")\n",
    "dataset[\"ddG_sen\"] = -1*dataset.F_FEN\n",
    "dataset[\"ddG_spe\"] = dataset.F_DEC-dataset.F_FEN\n",
    "dataset[\"sen_var\"] = dataset.err_FEN\n",
    "dataset[\"spe_var\"] = np.sqrt(dataset.err_FEN**2 + dataset.err_DEC**2)\n",
    "dataset.ddG_sen = (dataset.ddG_sen - dataset.ddG_sen.mean())/dataset.ddG_sen.std()\n",
    "dataset.sen_var = dataset.sen_var/dataset.ddG_sen.std()\n",
    "dataset.ddG_spe = (dataset.ddG_spe - dataset.ddG_spe.mean())/dataset.ddG_spe.std()\n",
    "dataset.spe_var = dataset.spe_var/dataset.ddG_spe.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Seq2Ascii(\"/project/andrewferguson/armin/HTVS_Fentanyl/MFMOBO/AA.blosum62.pckl\")\n",
    "\n",
    "fspace = []\n",
    "with open(\"/project/andrewferguson/armin/HTVS_Fentanyl/gen_input_space/full_space.txt\") as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        fspace.append(line.split()[0])\n",
    "        line = f.readline()\n",
    "\n",
    "translator.fit(fspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_x = translator.encode_to_int(dataset.PCC.to_list()).to(device)\n",
    "FE_sen = torch.tensor(dataset.ddG_sen.to_numpy()).float().to(device)\n",
    "FE_sen_var = torch.tensor(dataset.sen_var.to_numpy()).float().to(device)\n",
    "FE_spe = torch.tensor(dataset.ddG_spe.to_numpy()).float().to(device)\n",
    "FE_spe_var = torch.tensor(dataset.spe_var.to_numpy()).float().to(device)\n",
    "train_y = torch.cat([FE_sen.view(-1, 1), FE_spe.view(-1, 1)], dim=1)\n",
    "err_y = torch.cat([FE_sen_var.view(-1, 1), FE_spe_var.view(-1, 1)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, mll = initialize_model(encoded_x, train_y, err_y, translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCC</th>\n",
       "      <th>F_FEN</th>\n",
       "      <th>err_FEN</th>\n",
       "      <th>F_DEC</th>\n",
       "      <th>err_DEC</th>\n",
       "      <th>ddG_sen</th>\n",
       "      <th>ddG_spe</th>\n",
       "      <th>sen_var</th>\n",
       "      <th>spe_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHGGF</td>\n",
       "      <td>-7.458785</td>\n",
       "      <td>0.325139</td>\n",
       "      <td>-5.914494</td>\n",
       "      <td>0.117817</td>\n",
       "      <td>-0.309527</td>\n",
       "      <td>-0.294839</td>\n",
       "      <td>0.325139</td>\n",
       "      <td>0.345827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GTGSG</td>\n",
       "      <td>-6.978182</td>\n",
       "      <td>0.306770</td>\n",
       "      <td>-6.713622</td>\n",
       "      <td>0.434684</td>\n",
       "      <td>-0.439369</td>\n",
       "      <td>-0.731104</td>\n",
       "      <td>0.306770</td>\n",
       "      <td>0.532032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TERPF</td>\n",
       "      <td>-5.519027</td>\n",
       "      <td>0.114119</td>\n",
       "      <td>-4.606593</td>\n",
       "      <td>0.060435</td>\n",
       "      <td>-0.833582</td>\n",
       "      <td>-0.510241</td>\n",
       "      <td>0.114119</td>\n",
       "      <td>0.129133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WWWWW</td>\n",
       "      <td>-14.399965</td>\n",
       "      <td>0.466565</td>\n",
       "      <td>-6.271820</td>\n",
       "      <td>0.166044</td>\n",
       "      <td>1.565739</td>\n",
       "      <td>1.949624</td>\n",
       "      <td>0.466565</td>\n",
       "      <td>0.495231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GGDEK</td>\n",
       "      <td>-7.550094</td>\n",
       "      <td>0.305804</td>\n",
       "      <td>-5.107204</td>\n",
       "      <td>0.178314</td>\n",
       "      <td>-0.284858</td>\n",
       "      <td>0.011497</td>\n",
       "      <td>0.305804</td>\n",
       "      <td>0.353995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>YADAL</td>\n",
       "      <td>-9.317697</td>\n",
       "      <td>0.777650</td>\n",
       "      <td>-7.286629</td>\n",
       "      <td>0.428413</td>\n",
       "      <td>0.192687</td>\n",
       "      <td>-0.128894</td>\n",
       "      <td>0.777650</td>\n",
       "      <td>0.887850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HHHHH</td>\n",
       "      <td>-11.312336</td>\n",
       "      <td>0.459934</td>\n",
       "      <td>-9.105205</td>\n",
       "      <td>0.363219</td>\n",
       "      <td>0.731569</td>\n",
       "      <td>-0.068874</td>\n",
       "      <td>0.459934</td>\n",
       "      <td>0.586061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AWPVN</td>\n",
       "      <td>-9.215318</td>\n",
       "      <td>0.437208</td>\n",
       "      <td>-7.464716</td>\n",
       "      <td>0.241339</td>\n",
       "      <td>0.165027</td>\n",
       "      <td>-0.224507</td>\n",
       "      <td>0.437208</td>\n",
       "      <td>0.499395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GRGFG</td>\n",
       "      <td>-7.602260</td>\n",
       "      <td>0.106252</td>\n",
       "      <td>-7.410885</td>\n",
       "      <td>0.638032</td>\n",
       "      <td>-0.270765</td>\n",
       "      <td>-0.756053</td>\n",
       "      <td>0.106252</td>\n",
       "      <td>0.646818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PRHTS</td>\n",
       "      <td>-10.580213</td>\n",
       "      <td>0.359631</td>\n",
       "      <td>-7.314180</td>\n",
       "      <td>0.245566</td>\n",
       "      <td>0.533775</td>\n",
       "      <td>0.292110</td>\n",
       "      <td>0.359631</td>\n",
       "      <td>0.435474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FGGDG</td>\n",
       "      <td>-6.763720</td>\n",
       "      <td>0.166350</td>\n",
       "      <td>-5.872953</td>\n",
       "      <td>0.079713</td>\n",
       "      <td>-0.497309</td>\n",
       "      <td>-0.517628</td>\n",
       "      <td>0.166350</td>\n",
       "      <td>0.184463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WWWWL</td>\n",
       "      <td>-10.191345</td>\n",
       "      <td>0.341378</td>\n",
       "      <td>-6.587768</td>\n",
       "      <td>0.151628</td>\n",
       "      <td>0.428716</td>\n",
       "      <td>0.407180</td>\n",
       "      <td>0.341378</td>\n",
       "      <td>0.373537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GWGHG</td>\n",
       "      <td>-7.616007</td>\n",
       "      <td>0.271766</td>\n",
       "      <td>-7.153246</td>\n",
       "      <td>0.588014</td>\n",
       "      <td>-0.267051</td>\n",
       "      <td>-0.663537</td>\n",
       "      <td>0.271766</td>\n",
       "      <td>0.647779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LGGNG</td>\n",
       "      <td>-6.402710</td>\n",
       "      <td>0.284045</td>\n",
       "      <td>-5.610838</td>\n",
       "      <td>0.146017</td>\n",
       "      <td>-0.594841</td>\n",
       "      <td>-0.551341</td>\n",
       "      <td>0.284045</td>\n",
       "      <td>0.319379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AAAAA</td>\n",
       "      <td>-9.292998</td>\n",
       "      <td>0.326173</td>\n",
       "      <td>-8.197725</td>\n",
       "      <td>0.120473</td>\n",
       "      <td>0.186014</td>\n",
       "      <td>-0.447911</td>\n",
       "      <td>0.326173</td>\n",
       "      <td>0.347711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GHASF</td>\n",
       "      <td>-7.858374</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>-5.631227</td>\n",
       "      <td>0.167707</td>\n",
       "      <td>-0.201572</td>\n",
       "      <td>-0.062051</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.369102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WVRSP</td>\n",
       "      <td>-11.053547</td>\n",
       "      <td>1.792179</td>\n",
       "      <td>-5.995353</td>\n",
       "      <td>0.147899</td>\n",
       "      <td>0.661653</td>\n",
       "      <td>0.903065</td>\n",
       "      <td>1.792179</td>\n",
       "      <td>1.798272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PRWET</td>\n",
       "      <td>-10.642284</td>\n",
       "      <td>0.213585</td>\n",
       "      <td>-5.350175</td>\n",
       "      <td>0.367507</td>\n",
       "      <td>0.550544</td>\n",
       "      <td>0.982808</td>\n",
       "      <td>0.213585</td>\n",
       "      <td>0.425064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>REYHA</td>\n",
       "      <td>-10.151324</td>\n",
       "      <td>0.556083</td>\n",
       "      <td>-5.918806</td>\n",
       "      <td>0.188234</td>\n",
       "      <td>0.417904</td>\n",
       "      <td>0.621589</td>\n",
       "      <td>0.556083</td>\n",
       "      <td>0.587078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GGGGG</td>\n",
       "      <td>-6.343430</td>\n",
       "      <td>0.202233</td>\n",
       "      <td>-6.393005</td>\n",
       "      <td>0.216550</td>\n",
       "      <td>-0.610857</td>\n",
       "      <td>-0.838194</td>\n",
       "      <td>0.202233</td>\n",
       "      <td>0.296297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FDEGW</td>\n",
       "      <td>-2.059114</td>\n",
       "      <td>0.087678</td>\n",
       "      <td>-1.960926</td>\n",
       "      <td>0.049611</td>\n",
       "      <td>-1.768330</td>\n",
       "      <td>-0.787821</td>\n",
       "      <td>0.087678</td>\n",
       "      <td>0.100741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NRPAY</td>\n",
       "      <td>-7.116920</td>\n",
       "      <td>0.254831</td>\n",
       "      <td>-7.666638</td>\n",
       "      <td>0.418269</td>\n",
       "      <td>-0.401887</td>\n",
       "      <td>-1.008695</td>\n",
       "      <td>0.254831</td>\n",
       "      <td>0.489783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ASGWA</td>\n",
       "      <td>-7.022473</td>\n",
       "      <td>0.347787</td>\n",
       "      <td>-6.695064</td>\n",
       "      <td>0.247961</td>\n",
       "      <td>-0.427403</td>\n",
       "      <td>-0.709679</td>\n",
       "      <td>0.347787</td>\n",
       "      <td>0.427130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AGAGA</td>\n",
       "      <td>-8.943515</td>\n",
       "      <td>0.236695</td>\n",
       "      <td>-9.227345</td>\n",
       "      <td>0.143819</td>\n",
       "      <td>0.091596</td>\n",
       "      <td>-0.918053</td>\n",
       "      <td>0.236695</td>\n",
       "      <td>0.276963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KGGED</td>\n",
       "      <td>-6.490547</td>\n",
       "      <td>0.377022</td>\n",
       "      <td>-4.778479</td>\n",
       "      <td>0.179614</td>\n",
       "      <td>-0.571111</td>\n",
       "      <td>-0.237643</td>\n",
       "      <td>0.377022</td>\n",
       "      <td>0.417621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>YGGDL</td>\n",
       "      <td>-7.881777</td>\n",
       "      <td>0.451218</td>\n",
       "      <td>-6.275221</td>\n",
       "      <td>0.221867</td>\n",
       "      <td>-0.195249</td>\n",
       "      <td>-0.273612</td>\n",
       "      <td>0.451218</td>\n",
       "      <td>0.502815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>WWYHV</td>\n",
       "      <td>-11.306430</td>\n",
       "      <td>0.557719</td>\n",
       "      <td>-6.016158</td>\n",
       "      <td>0.156254</td>\n",
       "      <td>0.729973</td>\n",
       "      <td>0.982181</td>\n",
       "      <td>0.557719</td>\n",
       "      <td>0.579195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>WWWWY</td>\n",
       "      <td>-12.212253</td>\n",
       "      <td>0.366076</td>\n",
       "      <td>-6.744625</td>\n",
       "      <td>0.258400</td>\n",
       "      <td>0.974695</td>\n",
       "      <td>1.042643</td>\n",
       "      <td>0.366076</td>\n",
       "      <td>0.448087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RAWGS</td>\n",
       "      <td>0.362277</td>\n",
       "      <td>0.053563</td>\n",
       "      <td>0.977274</td>\n",
       "      <td>0.039738</td>\n",
       "      <td>-2.422506</td>\n",
       "      <td>-0.611639</td>\n",
       "      <td>0.053563</td>\n",
       "      <td>0.066694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PETSK</td>\n",
       "      <td>-21.804696</td>\n",
       "      <td>0.441747</td>\n",
       "      <td>-7.853450</td>\n",
       "      <td>0.111366</td>\n",
       "      <td>3.566239</td>\n",
       "      <td>3.934742</td>\n",
       "      <td>0.441747</td>\n",
       "      <td>0.455569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SGEGR</td>\n",
       "      <td>-6.304393</td>\n",
       "      <td>0.388708</td>\n",
       "      <td>-5.165393</td>\n",
       "      <td>0.197754</td>\n",
       "      <td>-0.621403</td>\n",
       "      <td>-0.433004</td>\n",
       "      <td>0.388708</td>\n",
       "      <td>0.436120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SKLYR</td>\n",
       "      <td>-8.313880</td>\n",
       "      <td>0.317993</td>\n",
       "      <td>-6.937612</td>\n",
       "      <td>0.315060</td>\n",
       "      <td>-0.078510</td>\n",
       "      <td>-0.352119</td>\n",
       "      <td>0.317993</td>\n",
       "      <td>0.447641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PCC      F_FEN   err_FEN     F_DEC   err_DEC   ddG_sen   ddG_spe  \\\n",
       "0   GHGGF  -7.458785  0.325139 -5.914494  0.117817 -0.309527 -0.294839   \n",
       "1   GTGSG  -6.978182  0.306770 -6.713622  0.434684 -0.439369 -0.731104   \n",
       "2   TERPF  -5.519027  0.114119 -4.606593  0.060435 -0.833582 -0.510241   \n",
       "3   WWWWW -14.399965  0.466565 -6.271820  0.166044  1.565739  1.949624   \n",
       "4   GGDEK  -7.550094  0.305804 -5.107204  0.178314 -0.284858  0.011497   \n",
       "5   YADAL  -9.317697  0.777650 -7.286629  0.428413  0.192687 -0.128894   \n",
       "6   HHHHH -11.312336  0.459934 -9.105205  0.363219  0.731569 -0.068874   \n",
       "7   AWPVN  -9.215318  0.437208 -7.464716  0.241339  0.165027 -0.224507   \n",
       "8   GRGFG  -7.602260  0.106252 -7.410885  0.638032 -0.270765 -0.756053   \n",
       "9   PRHTS -10.580213  0.359631 -7.314180  0.245566  0.533775  0.292110   \n",
       "10  FGGDG  -6.763720  0.166350 -5.872953  0.079713 -0.497309 -0.517628   \n",
       "11  WWWWL -10.191345  0.341378 -6.587768  0.151628  0.428716  0.407180   \n",
       "12  GWGHG  -7.616007  0.271766 -7.153246  0.588014 -0.267051 -0.663537   \n",
       "13  LGGNG  -6.402710  0.284045 -5.610838  0.146017 -0.594841 -0.551341   \n",
       "14  AAAAA  -9.292998  0.326173 -8.197725  0.120473  0.186014 -0.447911   \n",
       "15  GHASF  -7.858374  0.328802 -5.631227  0.167707 -0.201572 -0.062051   \n",
       "16  WVRSP -11.053547  1.792179 -5.995353  0.147899  0.661653  0.903065   \n",
       "17  PRWET -10.642284  0.213585 -5.350175  0.367507  0.550544  0.982808   \n",
       "18  REYHA -10.151324  0.556083 -5.918806  0.188234  0.417904  0.621589   \n",
       "19  GGGGG  -6.343430  0.202233 -6.393005  0.216550 -0.610857 -0.838194   \n",
       "20  FDEGW  -2.059114  0.087678 -1.960926  0.049611 -1.768330 -0.787821   \n",
       "21  NRPAY  -7.116920  0.254831 -7.666638  0.418269 -0.401887 -1.008695   \n",
       "22  ASGWA  -7.022473  0.347787 -6.695064  0.247961 -0.427403 -0.709679   \n",
       "23  AGAGA  -8.943515  0.236695 -9.227345  0.143819  0.091596 -0.918053   \n",
       "24  KGGED  -6.490547  0.377022 -4.778479  0.179614 -0.571111 -0.237643   \n",
       "25  YGGDL  -7.881777  0.451218 -6.275221  0.221867 -0.195249 -0.273612   \n",
       "26  WWYHV -11.306430  0.557719 -6.016158  0.156254  0.729973  0.982181   \n",
       "27  WWWWY -12.212253  0.366076 -6.744625  0.258400  0.974695  1.042643   \n",
       "28  RAWGS   0.362277  0.053563  0.977274  0.039738 -2.422506 -0.611639   \n",
       "29  PETSK -21.804696  0.441747 -7.853450  0.111366  3.566239  3.934742   \n",
       "30  SGEGR  -6.304393  0.388708 -5.165393  0.197754 -0.621403 -0.433004   \n",
       "31  SKLYR  -8.313880  0.317993 -6.937612  0.315060 -0.078510 -0.352119   \n",
       "\n",
       "     sen_var   spe_var  \n",
       "0   0.325139  0.345827  \n",
       "1   0.306770  0.532032  \n",
       "2   0.114119  0.129133  \n",
       "3   0.466565  0.495231  \n",
       "4   0.305804  0.353995  \n",
       "5   0.777650  0.887850  \n",
       "6   0.459934  0.586061  \n",
       "7   0.437208  0.499395  \n",
       "8   0.106252  0.646818  \n",
       "9   0.359631  0.435474  \n",
       "10  0.166350  0.184463  \n",
       "11  0.341378  0.373537  \n",
       "12  0.271766  0.647779  \n",
       "13  0.284045  0.319379  \n",
       "14  0.326173  0.347711  \n",
       "15  0.328802  0.369102  \n",
       "16  1.792179  1.798272  \n",
       "17  0.213585  0.425064  \n",
       "18  0.556083  0.587078  \n",
       "19  0.202233  0.296297  \n",
       "20  0.087678  0.100741  \n",
       "21  0.254831  0.489783  \n",
       "22  0.347787  0.427130  \n",
       "23  0.236695  0.276963  \n",
       "24  0.377022  0.417621  \n",
       "25  0.451218  0.502815  \n",
       "26  0.557719  0.579195  \n",
       "27  0.366076  0.448087  \n",
       "28  0.053563  0.066694  \n",
       "29  0.441747  0.455569  \n",
       "30  0.388708  0.436120  \n",
       "31  0.317993  0.447641  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del fspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SumMarginalLogLikelihood(\n",
       "  (likelihood): LikelihoodList(\n",
       "    (likelihoods): ModuleList(\n",
       "      (0-1): 2 x FixedNoiseGaussianLikelihood(\n",
       "        (noise_covar): FixedGaussianNoise()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (model): ModelListGP(\n",
       "    (models): ModuleList(\n",
       "      (0-1): 2 x GaussianStringKernelGP(\n",
       "        (likelihood): FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "        (mean_module): ConstantMean()\n",
       "        (covar_module): GenericStringKernel(\n",
       "          (raw_sigma1_constraint): Positive()\n",
       "          (raw_sigma2_constraint): Positive()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (likelihood): LikelihoodList(\n",
       "      (likelihoods): ModuleList(\n",
       "        (0-1): 2 x FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlls): ModuleList(\n",
       "    (0-1): 2 x ExactMarginalLogLikelihood(\n",
       "      (likelihood): FixedNoiseGaussianLikelihood(\n",
       "        (noise_covar): FixedGaussianNoise()\n",
       "      )\n",
       "      (model): GaussianStringKernelGP(\n",
       "        (likelihood): FixedNoiseGaussianLikelihood(\n",
       "          (noise_covar): FixedGaussianNoise()\n",
       "        )\n",
       "        (mean_module): ConstantMean()\n",
       "        (covar_module): GenericStringKernel(\n",
       "          (raw_sigma1_constraint): Positive()\n",
       "          (raw_sigma2_constraint): Positive()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_gpytorch_mll(mll)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.train()\n",
    "mll.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "fit_gpytorch_model(mll, optimizer, n_iters=500)\n",
    "model.eval()\n",
    "mll.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_space = torch.as_tensor(list(translator.int2str.keys())).view(-1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = model.posterior(full_space[::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.errorbar(x = post.mean[:, 0].detach().numpy(), y = post.mean[:, 1].detach().numpy(), xerr=post.variance[:, 0].sqrt().detach().numpy(), yerr=post.variance[:, 1].sqrt().detach().numpy(), fmt='o')\n",
    "plt.scatter(x = post.mean[:, 0].detach().numpy(), y = post.mean[:, 1].detach().numpy(), color='blue', label=\"Predicted\")\n",
    "plt.scatter(x = train_y[:, 0].detach().numpy(), y = train_y[:, 1].detach().numpy(), color='red', label=\"Training\")\n",
    "new_x = [\"WWWWL\", \"WWWWY\", \"WWYHV\"]\n",
    "new_x = translator.encode_to_int(new_x).to(device)\n",
    "plt.scatter(x = post.mean[new_x, 0].detach().numpy(), y = post.mean[new_x, 1].detach().numpy(), color='green', label=\"New Candidates\")\n",
    "plt.xlabel(r\"-$\\Delta G_{FEN}$\")\n",
    "plt.ylabel(r\"$\\Delta G_{DEC}-\\Delta G_{FEN}$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_train = model.posterior(encoded_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x = post_train.mean[:, 0].detach().numpy(), y = post_train.mean[:, 1].detach().numpy(),\n",
    "             xerr=post_train.variance[:, 0].sqrt().detach().numpy(), yerr=post_train.variance[:, 1].sqrt().detach().numpy(), fmt='o', label=\"Predicted\")\n",
    "plt.errorbar(x = train_y[:, 0].detach().numpy(), y = train_y[:, 1].detach().numpy(),\n",
    "             xerr=err_y[:, 0].sqrt().detach().numpy(), yerr=err_y[:, 1].sqrt().detach().numpy(), fmt='o', label=\"Training\")\n",
    "plt.xlabel(r\"-$\\Delta G_{FEN}$\")\n",
    "plt.ylabel(r\"$\\Delta G_{DEC}-\\Delta G_{FEN}$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(dataset.PCC.to_list(), post_train.mean[:, 0].detach().numpy()-train_y[:, 0].detach().numpy(),\n",
    "        yerr=post_train.variance[:, 0].sqrt().detach().numpy(), label=\"Senstivity\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(dataset.PCC.to_list(), post_train.mean[:, 1].detach().numpy()-train_y[:, 1].detach().numpy(),\n",
    "        yerr=post_train.variance[:, 1].sqrt().detach().numpy(), label=\"Specificity\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (torch)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
